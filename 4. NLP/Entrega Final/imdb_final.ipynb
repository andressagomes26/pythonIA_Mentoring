{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNTP5dwUEoET"
      },
      "source": [
        "### Avaliacao Final\n",
        "\n",
        "> Aluna: Andressa Gomes Moreira\n",
        "\n",
        "> Dataset: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X7SO6llPEoEZ"
      },
      "outputs": [],
      "source": [
        "# Importações\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c9kzh9AsEoEa"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.layers import Input, Dense, SimpleRNN, Dropout\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Layer\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras import Model\n",
        "\n",
        "import keras.backend as K\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keras.models import Sequential\n",
        "from keras.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkf2RqjLEoEb"
      },
      "source": [
        "#### Análise dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GWxRbGsDEoEc",
        "outputId": "3a8f0930-fdae-4741-a5ba-38cef521bf31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26625247-38e7-4eb3-a5fe-dd55fdf5cf18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26625247-38e7-4eb3-a5fe-dd55fdf5cf18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26625247-38e7-4eb3-a5fe-dd55fdf5cf18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26625247-38e7-4eb3-a5fe-dd55fdf5cf18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Dataset\n",
        "df = pd.read_table(\"IMDB Dataset.csv\", sep =',')\n",
        "df.head()  #df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "x8HQoPM8EoEd",
        "outputId": "bd45bec2-8d23-4686-975e-1c3caa87a855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df['review'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53939K0WEoEd"
      },
      "source": [
        "#### Limpeza dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "P4EwOAQDEoEe",
        "outputId": "763b927c-fe96-41c8-ce38-d5ced424ea9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a wonderful little production the filming technique is very unassuming very old time bbc fashion and gives comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is terrificly written and performed piece masterful production about one of the great master of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwell murals decorating every surface are terribly well done '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def limpezaDados(text):\n",
        "    # Remove Tags html\n",
        "    text_Tags = re.compile('<.*?>')    \n",
        "    text = text_Tags.sub(r'', text)\n",
        "    # Remove url\n",
        "    text_url=re.compile(r\"https://\\S+|http://\\S+\")\n",
        "    text=text_url.sub(r\" \", text)\n",
        "    # Remove pontuações\n",
        "    text_pont=re.compile(r\"[^\\w\\s]\")\n",
        "    text=text_pont.sub(r\" \", text)\n",
        "    # Remove dígitos\n",
        "    text_dig=re.compile(r\"\\d{1,}\")\n",
        "    text=text_dig.sub(r\" \", text)\n",
        "    # Remove caractere único\n",
        "    text_caract=re.compile(r\"\\s\\w\\s\")\n",
        "    text=text_caract.sub(r\" \",text)\n",
        "    # Remove múltiplos espaços\n",
        "    text_esp=re.compile(r\"\\s{2,}\")                    \n",
        "    text=text_esp.sub(r\" \",text)\n",
        "    \n",
        "    return text.lower()  # Texto minúsculo\n",
        "\n",
        "df['review'] = df['review'].apply(limpezaDados)\n",
        "df['review'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TDg9rkCEoEe"
      },
      "source": [
        "#### Tratamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNhW1xuQEoEf",
        "outputId": "d8fab5e7-d179-4572-83e2-f7b86a745a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Define as Stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G4YNS1vEoEg",
        "outputId": "ef1f6ba6-0249-43d6-b1d7-3bce604f1d6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "XSh7LjoQEoEg",
        "outputId": "6bac2e0c-ff53-4673-8661-bc630d1ba115"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wonderful little production filming technique unassuming old time bbc fashion gives comforting sometimes discomforting sense realism entire piece actors extremely well chosen michael sheen got polari voices pat truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master comedy life realism really comes home little things fantasy guard rather use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell murals decorating every surface terribly well done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Remover Sotpwords\n",
        "def remove_stopwords(text):\n",
        "    text_semStopw=[]\n",
        "    for word in text.split():\n",
        "        if word not in stopwords:\n",
        "            text_semStopw.append(word)\n",
        "    return \" \".join(text_semStopw)\n",
        "\n",
        "df['review']=df['review'].apply(remove_stopwords)\n",
        "df['review'][1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reviews - Coluna 'review' = dados\n",
        "# sentiment - Coluna 'sentiment' = Valores 'positive' e 'negative'\n",
        "# labels = Labels em valores numéricos\n",
        "\n",
        "reviews = df['review'].values\n",
        "sentiment = df['sentiment'].values\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(sentiment)\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htAKlhB-Fv2c",
        "outputId": "bbe630a3-a5b4-44ef-c346-69e896162ee9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = to_categorical(labels, num_classes=2).astype(int)"
      ],
      "metadata": {
        "id": "DR3eRMeNMFkn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W0snnfCEoEh"
      },
      "source": [
        "#### Divisão dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_0JoIm4UEoEi"
      },
      "outputs": [],
      "source": [
        "# Divisão dos dados em treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(reviews, label, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define os Tokens\n",
        "tokens = Tokenizer(num_words = 3000, oov_token='')\n",
        "tokens.fit_on_texts(X_train)\n",
        "word_index = tokens.word_index\n",
        "\n",
        "X_train = tokens.texts_to_sequences(X_train)\n",
        "X_train_pad = pad_sequences(X_train, padding='post', maxlen=200)\n",
        "\n",
        "X_test = tokens.texts_to_sequences(X_test)\n",
        "X_test_pad = pad_sequences(X_test, padding='post', maxlen=200)"
      ],
      "metadata": {
        "id": "fkv_BYykai6i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_pad.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test_pad.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "uTwpHXLRGapz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819e3b30-3482-457e-fa9f-b2e0f2bb5c30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 200)\n",
            "(40000, 2)\n",
            "(10000, 200)\n",
            "(10000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Criação do modelo"
      ],
      "metadata": {
        "id": "_kH_OTNMF9nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(3000, 100, input_length=200))\n",
        "model.add(Bidirectional(LSTM(128)))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR3HMFZcIrT0",
        "outputId": "d2f4c22f-377c-4a0f-ac8e-34ff1416bb9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 100)          300000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 256)              234496    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 551,074\n",
            "Trainable params: 551,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch1 = len(X_train_pad)/256"
      ],
      "metadata": {
        "id": "JHsbXgW9qDcA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train_pad, y_train, epochs=500, verbose=1,\n",
        "                    steps_per_epoch = steps_per_epoch1, batch_size = 256,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzCL9kDoKWXD",
        "outputId": "b65f7122-7a8f-463d-ce78-bd8bb54facca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "156/156 [==============================] - 15s 48ms/step - loss: 0.4230 - accuracy: 0.7932 - val_loss: 0.3299 - val_accuracy: 0.8710\n",
            "Epoch 2/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.2625 - accuracy: 0.8990 - val_loss: 0.3296 - val_accuracy: 0.8622\n",
            "Epoch 3/500\n",
            "156/156 [==============================] - 7s 47ms/step - loss: 0.2442 - accuracy: 0.9062 - val_loss: 0.3400 - val_accuracy: 0.8714\n",
            "Epoch 4/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.2145 - accuracy: 0.9188 - val_loss: 0.3679 - val_accuracy: 0.8701\n",
            "Epoch 5/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.1885 - accuracy: 0.9305 - val_loss: 0.3949 - val_accuracy: 0.8634\n",
            "Epoch 6/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.1752 - accuracy: 0.9359 - val_loss: 0.3922 - val_accuracy: 0.8511\n",
            "Epoch 7/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 0.1589 - accuracy: 0.9427 - val_loss: 0.4458 - val_accuracy: 0.8561\n",
            "Epoch 8/500\n",
            "156/156 [==============================] - 8s 49ms/step - loss: 0.1583 - accuracy: 0.9445 - val_loss: 0.4665 - val_accuracy: 0.8529\n",
            "Epoch 9/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.1158 - accuracy: 0.9612 - val_loss: 0.5609 - val_accuracy: 0.8430\n",
            "Epoch 10/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.1083 - accuracy: 0.9633 - val_loss: 0.5614 - val_accuracy: 0.8326\n",
            "Epoch 11/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0904 - accuracy: 0.9712 - val_loss: 0.5994 - val_accuracy: 0.8372\n",
            "Epoch 12/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 0.6660 - val_accuracy: 0.8429\n",
            "Epoch 13/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0529 - accuracy: 0.9851 - val_loss: 0.8122 - val_accuracy: 0.8431\n",
            "Epoch 14/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.7792 - val_accuracy: 0.8363\n",
            "Epoch 15/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0617 - accuracy: 0.9804 - val_loss: 0.7596 - val_accuracy: 0.8396\n",
            "Epoch 16/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 0.8327 - val_accuracy: 0.8339\n",
            "Epoch 17/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.9220 - val_accuracy: 0.8344\n",
            "Epoch 18/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0421 - accuracy: 0.9871 - val_loss: 0.8699 - val_accuracy: 0.8248\n",
            "Epoch 19/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.9977 - val_accuracy: 0.8379\n",
            "Epoch 20/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 1.1185 - val_accuracy: 0.8300\n",
            "Epoch 21/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.9463 - val_accuracy: 0.8202\n",
            "Epoch 22/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 1.1265 - val_accuracy: 0.8234\n",
            "Epoch 23/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 1.0119 - val_accuracy: 0.8298\n",
            "Epoch 24/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 1.1792 - val_accuracy: 0.8280\n",
            "Epoch 25/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 1.2146 - val_accuracy: 0.8321\n",
            "Epoch 26/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.2680 - val_accuracy: 0.8304\n",
            "Epoch 27/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.2973 - val_accuracy: 0.8304\n",
            "Epoch 28/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 1.1272 - val_accuracy: 0.8355\n",
            "Epoch 29/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 1.2106 - val_accuracy: 0.8430\n",
            "Epoch 30/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 1.0733 - val_accuracy: 0.8420\n",
            "Epoch 31/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0426 - accuracy: 0.9856 - val_loss: 0.9816 - val_accuracy: 0.8353\n",
            "Epoch 32/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 1.1687 - val_accuracy: 0.8344\n",
            "Epoch 33/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 1.2419 - val_accuracy: 0.8275\n",
            "Epoch 34/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.4273 - val_accuracy: 0.8320\n",
            "Epoch 35/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 1.1324 - val_accuracy: 0.8440\n",
            "Epoch 36/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.2619 - val_accuracy: 0.8374\n",
            "Epoch 37/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.4101 - val_accuracy: 0.8360\n",
            "Epoch 38/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.3584 - val_accuracy: 0.8301\n",
            "Epoch 39/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 1.2784 - val_accuracy: 0.8290\n",
            "Epoch 40/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.4068 - val_accuracy: 0.8335\n",
            "Epoch 41/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.8871e-04 - accuracy: 1.0000 - val_loss: 1.5508 - val_accuracy: 0.8363\n",
            "Epoch 42/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0123e-04 - accuracy: 1.0000 - val_loss: 1.6153 - val_accuracy: 0.8375\n",
            "Epoch 43/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.7070e-05 - accuracy: 1.0000 - val_loss: 1.6687 - val_accuracy: 0.8372\n",
            "Epoch 44/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.0380e-05 - accuracy: 1.0000 - val_loss: 1.7118 - val_accuracy: 0.8380\n",
            "Epoch 45/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.9212e-05 - accuracy: 1.0000 - val_loss: 1.7476 - val_accuracy: 0.8375\n",
            "Epoch 46/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.2947e-05 - accuracy: 1.0000 - val_loss: 1.7835 - val_accuracy: 0.8378\n",
            "Epoch 47/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.7080e-05 - accuracy: 1.0000 - val_loss: 1.8135 - val_accuracy: 0.8376\n",
            "Epoch 48/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.2693e-05 - accuracy: 1.0000 - val_loss: 1.8417 - val_accuracy: 0.8374\n",
            "Epoch 49/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.9521e-05 - accuracy: 1.0000 - val_loss: 1.8710 - val_accuracy: 0.8375\n",
            "Epoch 50/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.7222e-05 - accuracy: 1.0000 - val_loss: 1.8960 - val_accuracy: 0.8374\n",
            "Epoch 51/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.4476e-05 - accuracy: 1.0000 - val_loss: 1.9213 - val_accuracy: 0.8372\n",
            "Epoch 52/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.2662e-05 - accuracy: 1.0000 - val_loss: 1.9449 - val_accuracy: 0.8375\n",
            "Epoch 53/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.1393e-05 - accuracy: 1.0000 - val_loss: 1.9677 - val_accuracy: 0.8375\n",
            "Epoch 54/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.9400e-06 - accuracy: 1.0000 - val_loss: 1.9907 - val_accuracy: 0.8370\n",
            "Epoch 55/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.7922e-06 - accuracy: 1.0000 - val_loss: 2.0126 - val_accuracy: 0.8370\n",
            "Epoch 56/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 7.6670e-06 - accuracy: 1.0000 - val_loss: 2.0329 - val_accuracy: 0.8370\n",
            "Epoch 57/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.9991e-06 - accuracy: 1.0000 - val_loss: 2.0546 - val_accuracy: 0.8367\n",
            "Epoch 58/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.2253e-06 - accuracy: 1.0000 - val_loss: 2.0747 - val_accuracy: 0.8370\n",
            "Epoch 59/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.5103e-06 - accuracy: 1.0000 - val_loss: 2.0949 - val_accuracy: 0.8369\n",
            "Epoch 60/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.9042e-06 - accuracy: 1.0000 - val_loss: 2.1143 - val_accuracy: 0.8370\n",
            "Epoch 61/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.5488e-06 - accuracy: 1.0000 - val_loss: 2.1337 - val_accuracy: 0.8367\n",
            "Epoch 62/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.9886e-06 - accuracy: 1.0000 - val_loss: 2.1530 - val_accuracy: 0.8366\n",
            "Epoch 63/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.6656e-06 - accuracy: 1.0000 - val_loss: 2.1719 - val_accuracy: 0.8367\n",
            "Epoch 64/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.2446e-06 - accuracy: 1.0000 - val_loss: 2.1911 - val_accuracy: 0.8371\n",
            "Epoch 65/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.0378e-06 - accuracy: 1.0000 - val_loss: 2.2096 - val_accuracy: 0.8370\n",
            "Epoch 66/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.6729e-06 - accuracy: 1.0000 - val_loss: 2.2275 - val_accuracy: 0.8371\n",
            "Epoch 67/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.3382e-06 - accuracy: 1.0000 - val_loss: 2.2455 - val_accuracy: 0.8370\n",
            "Epoch 68/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.2257e-06 - accuracy: 1.0000 - val_loss: 2.2639 - val_accuracy: 0.8369\n",
            "Epoch 69/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.0205e-06 - accuracy: 1.0000 - val_loss: 2.2810 - val_accuracy: 0.8370\n",
            "Epoch 70/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.7737e-06 - accuracy: 1.0000 - val_loss: 2.2992 - val_accuracy: 0.8372\n",
            "Epoch 71/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.6450e-06 - accuracy: 1.0000 - val_loss: 2.3159 - val_accuracy: 0.8372\n",
            "Epoch 72/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.4941e-06 - accuracy: 1.0000 - val_loss: 2.3335 - val_accuracy: 0.8371\n",
            "Epoch 73/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.3311e-06 - accuracy: 1.0000 - val_loss: 2.3510 - val_accuracy: 0.8375\n",
            "Epoch 74/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.2411e-06 - accuracy: 1.0000 - val_loss: 2.3683 - val_accuracy: 0.8372\n",
            "Epoch 75/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.1039e-06 - accuracy: 1.0000 - val_loss: 2.3851 - val_accuracy: 0.8371\n",
            "Epoch 76/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0347e-06 - accuracy: 1.0000 - val_loss: 2.4030 - val_accuracy: 0.8370\n",
            "Epoch 77/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.3185e-07 - accuracy: 1.0000 - val_loss: 2.4192 - val_accuracy: 0.8370\n",
            "Epoch 78/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.2976e-07 - accuracy: 1.0000 - val_loss: 2.4357 - val_accuracy: 0.8366\n",
            "Epoch 79/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 7.6901e-07 - accuracy: 1.0000 - val_loss: 2.4524 - val_accuracy: 0.8367\n",
            "Epoch 80/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.7153e-07 - accuracy: 1.0000 - val_loss: 2.4688 - val_accuracy: 0.8366\n",
            "Epoch 81/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.6993e-07 - accuracy: 1.0000 - val_loss: 2.4850 - val_accuracy: 0.8365\n",
            "Epoch 82/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.8027e-07 - accuracy: 1.0000 - val_loss: 2.5012 - val_accuracy: 0.8366\n",
            "Epoch 83/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.2521e-07 - accuracy: 1.0000 - val_loss: 2.5173 - val_accuracy: 0.8366\n",
            "Epoch 84/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.9533e-07 - accuracy: 1.0000 - val_loss: 2.5339 - val_accuracy: 0.8366\n",
            "Epoch 85/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.3460e-07 - accuracy: 1.0000 - val_loss: 2.5499 - val_accuracy: 0.8365\n",
            "Epoch 86/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.0868e-07 - accuracy: 1.0000 - val_loss: 2.5655 - val_accuracy: 0.8366\n",
            "Epoch 87/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.6503e-07 - accuracy: 1.0000 - val_loss: 2.5813 - val_accuracy: 0.8367\n",
            "Epoch 88/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.3875e-07 - accuracy: 1.0000 - val_loss: 2.5973 - val_accuracy: 0.8369\n",
            "Epoch 89/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.1732e-07 - accuracy: 1.0000 - val_loss: 2.6132 - val_accuracy: 0.8370\n",
            "Epoch 90/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.7506e-07 - accuracy: 1.0000 - val_loss: 2.6284 - val_accuracy: 0.8371\n",
            "Epoch 91/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.6290e-07 - accuracy: 1.0000 - val_loss: 2.6444 - val_accuracy: 0.8372\n",
            "Epoch 92/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.2914e-07 - accuracy: 1.0000 - val_loss: 2.6604 - val_accuracy: 0.8372\n",
            "Epoch 93/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.1759e-07 - accuracy: 1.0000 - val_loss: 2.6748 - val_accuracy: 0.8372\n",
            "Epoch 94/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.9740e-07 - accuracy: 1.0000 - val_loss: 2.6898 - val_accuracy: 0.8372\n",
            "Epoch 95/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.8457e-07 - accuracy: 1.0000 - val_loss: 2.7046 - val_accuracy: 0.8371\n",
            "Epoch 96/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.6052e-07 - accuracy: 1.0000 - val_loss: 2.7209 - val_accuracy: 0.8370\n",
            "Epoch 97/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.5449e-07 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.8370\n",
            "Epoch 98/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.3625e-07 - accuracy: 1.0000 - val_loss: 2.7504 - val_accuracy: 0.8369\n",
            "Epoch 99/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.2890e-07 - accuracy: 1.0000 - val_loss: 2.7643 - val_accuracy: 0.8370\n",
            "Epoch 100/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.1476e-07 - accuracy: 1.0000 - val_loss: 2.7803 - val_accuracy: 0.8370\n",
            "Epoch 101/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0922e-07 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.8370\n",
            "Epoch 102/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.6463e-08 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.8371\n",
            "Epoch 103/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.0762e-08 - accuracy: 1.0000 - val_loss: 2.8246 - val_accuracy: 0.8370\n",
            "Epoch 104/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.1219e-08 - accuracy: 1.0000 - val_loss: 2.8388 - val_accuracy: 0.8370\n",
            "Epoch 105/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 7.5209e-08 - accuracy: 1.0000 - val_loss: 2.8525 - val_accuracy: 0.8370\n",
            "Epoch 106/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.8847e-08 - accuracy: 1.0000 - val_loss: 2.8671 - val_accuracy: 0.8370\n",
            "Epoch 107/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.3230e-08 - accuracy: 1.0000 - val_loss: 2.8809 - val_accuracy: 0.8370\n",
            "Epoch 108/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.9392e-08 - accuracy: 1.0000 - val_loss: 2.8950 - val_accuracy: 0.8370\n",
            "Epoch 109/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.3052e-08 - accuracy: 1.0000 - val_loss: 2.9091 - val_accuracy: 0.8370\n",
            "Epoch 110/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.9374e-08 - accuracy: 1.0000 - val_loss: 2.9236 - val_accuracy: 0.8372\n",
            "Epoch 111/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.5878e-08 - accuracy: 1.0000 - val_loss: 2.9376 - val_accuracy: 0.8374\n",
            "Epoch 112/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.1011e-08 - accuracy: 1.0000 - val_loss: 2.9503 - val_accuracy: 0.8376\n",
            "Epoch 113/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.8400e-08 - accuracy: 1.0000 - val_loss: 2.9644 - val_accuracy: 0.8374\n",
            "Epoch 114/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.5302e-08 - accuracy: 1.0000 - val_loss: 2.9781 - val_accuracy: 0.8374\n",
            "Epoch 115/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.2937e-08 - accuracy: 1.0000 - val_loss: 2.9923 - val_accuracy: 0.8374\n",
            "Epoch 116/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.9681e-08 - accuracy: 1.0000 - val_loss: 3.0054 - val_accuracy: 0.8375\n",
            "Epoch 117/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.7662e-08 - accuracy: 1.0000 - val_loss: 3.0187 - val_accuracy: 0.8372\n",
            "Epoch 118/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.5305e-08 - accuracy: 1.0000 - val_loss: 3.0316 - val_accuracy: 0.8376\n",
            "Epoch 119/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.3367e-08 - accuracy: 1.0000 - val_loss: 3.0441 - val_accuracy: 0.8375\n",
            "Epoch 120/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.1911e-08 - accuracy: 1.0000 - val_loss: 3.0585 - val_accuracy: 0.8372\n",
            "Epoch 121/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.9792e-08 - accuracy: 1.0000 - val_loss: 3.0713 - val_accuracy: 0.8375\n",
            "Epoch 122/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.8688e-08 - accuracy: 1.0000 - val_loss: 3.0848 - val_accuracy: 0.8372\n",
            "Epoch 123/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.6667e-08 - accuracy: 1.0000 - val_loss: 3.0972 - val_accuracy: 0.8372\n",
            "Epoch 124/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.5647e-08 - accuracy: 1.0000 - val_loss: 3.1097 - val_accuracy: 0.8372\n",
            "Epoch 125/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.4508e-08 - accuracy: 1.0000 - val_loss: 3.1228 - val_accuracy: 0.8371\n",
            "Epoch 126/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.3622e-08 - accuracy: 1.0000 - val_loss: 3.1354 - val_accuracy: 0.8371\n",
            "Epoch 127/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.2424e-08 - accuracy: 1.0000 - val_loss: 3.1476 - val_accuracy: 0.8372\n",
            "Epoch 128/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.1422e-08 - accuracy: 1.0000 - val_loss: 3.1604 - val_accuracy: 0.8372\n",
            "Epoch 129/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0593e-08 - accuracy: 1.0000 - val_loss: 3.1721 - val_accuracy: 0.8372\n",
            "Epoch 130/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0029e-08 - accuracy: 1.0000 - val_loss: 3.1845 - val_accuracy: 0.8372\n",
            "Epoch 131/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.0247e-09 - accuracy: 1.0000 - val_loss: 3.1967 - val_accuracy: 0.8374\n",
            "Epoch 132/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.4198e-09 - accuracy: 1.0000 - val_loss: 3.2080 - val_accuracy: 0.8375\n",
            "Epoch 133/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.0207e-09 - accuracy: 1.0000 - val_loss: 3.2205 - val_accuracy: 0.8375\n",
            "Epoch 134/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 7.4284e-09 - accuracy: 1.0000 - val_loss: 3.2321 - val_accuracy: 0.8375\n",
            "Epoch 135/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.9184e-09 - accuracy: 1.0000 - val_loss: 3.2432 - val_accuracy: 0.8375\n",
            "Epoch 136/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.1851e-09 - accuracy: 1.0000 - val_loss: 3.2562 - val_accuracy: 0.8375\n",
            "Epoch 137/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.9612e-09 - accuracy: 1.0000 - val_loss: 3.2661 - val_accuracy: 0.8374\n",
            "Epoch 138/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.6204e-09 - accuracy: 1.0000 - val_loss: 3.2783 - val_accuracy: 0.8375\n",
            "Epoch 139/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.1587e-09 - accuracy: 1.0000 - val_loss: 3.2886 - val_accuracy: 0.8375\n",
            "Epoch 140/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.7164e-09 - accuracy: 1.0000 - val_loss: 3.3003 - val_accuracy: 0.8374\n",
            "Epoch 141/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.5656e-09 - accuracy: 1.0000 - val_loss: 3.3106 - val_accuracy: 0.8372\n",
            "Epoch 142/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.2138e-09 - accuracy: 1.0000 - val_loss: 3.3224 - val_accuracy: 0.8371\n",
            "Epoch 143/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.8533e-09 - accuracy: 1.0000 - val_loss: 3.3319 - val_accuracy: 0.8372\n",
            "Epoch 144/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.7055e-09 - accuracy: 1.0000 - val_loss: 3.3421 - val_accuracy: 0.8372\n",
            "Epoch 145/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.4653e-09 - accuracy: 1.0000 - val_loss: 3.3524 - val_accuracy: 0.8375\n",
            "Epoch 146/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.2305e-09 - accuracy: 1.0000 - val_loss: 3.3640 - val_accuracy: 0.8378\n",
            "Epoch 147/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.0572e-09 - accuracy: 1.0000 - val_loss: 3.3737 - val_accuracy: 0.8375\n",
            "Epoch 148/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.8542e-09 - accuracy: 1.0000 - val_loss: 3.3825 - val_accuracy: 0.8376\n",
            "Epoch 149/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.7602e-09 - accuracy: 1.0000 - val_loss: 3.3932 - val_accuracy: 0.8376\n",
            "Epoch 150/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.5651e-09 - accuracy: 1.0000 - val_loss: 3.4032 - val_accuracy: 0.8375\n",
            "Epoch 151/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.3307e-09 - accuracy: 1.0000 - val_loss: 3.4125 - val_accuracy: 0.8374\n",
            "Epoch 152/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.2524e-09 - accuracy: 1.0000 - val_loss: 3.4215 - val_accuracy: 0.8376\n",
            "Epoch 153/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.1626e-09 - accuracy: 1.0000 - val_loss: 3.4306 - val_accuracy: 0.8375\n",
            "Epoch 154/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.0011e-09 - accuracy: 1.0000 - val_loss: 3.4389 - val_accuracy: 0.8380\n",
            "Epoch 155/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.9363e-09 - accuracy: 1.0000 - val_loss: 3.4462 - val_accuracy: 0.8378\n",
            "Epoch 156/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.8076e-09 - accuracy: 1.0000 - val_loss: 3.4558 - val_accuracy: 0.8381\n",
            "Epoch 157/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.7043e-09 - accuracy: 1.0000 - val_loss: 3.4629 - val_accuracy: 0.8378\n",
            "Epoch 158/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.6884e-09 - accuracy: 1.0000 - val_loss: 3.4713 - val_accuracy: 0.8379\n",
            "Epoch 159/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.5206e-09 - accuracy: 1.0000 - val_loss: 3.4794 - val_accuracy: 0.8381\n",
            "Epoch 160/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.5038e-09 - accuracy: 1.0000 - val_loss: 3.4864 - val_accuracy: 0.8379\n",
            "Epoch 161/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.4108e-09 - accuracy: 1.0000 - val_loss: 3.4932 - val_accuracy: 0.8378\n",
            "Epoch 162/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.3662e-09 - accuracy: 1.0000 - val_loss: 3.5011 - val_accuracy: 0.8380\n",
            "Epoch 163/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.2955e-09 - accuracy: 1.0000 - val_loss: 3.5088 - val_accuracy: 0.8380\n",
            "Epoch 164/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.2309e-09 - accuracy: 1.0000 - val_loss: 3.5163 - val_accuracy: 0.8380\n",
            "Epoch 165/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.1993e-09 - accuracy: 1.0000 - val_loss: 3.5242 - val_accuracy: 0.8381\n",
            "Epoch 166/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.1354e-09 - accuracy: 1.0000 - val_loss: 3.5304 - val_accuracy: 0.8380\n",
            "Epoch 167/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0863e-09 - accuracy: 1.0000 - val_loss: 3.5356 - val_accuracy: 0.8379\n",
            "Epoch 168/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0749e-09 - accuracy: 1.0000 - val_loss: 3.5420 - val_accuracy: 0.8378\n",
            "Epoch 169/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 1.0171e-09 - accuracy: 1.0000 - val_loss: 3.5489 - val_accuracy: 0.8380\n",
            "Epoch 170/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.9564e-10 - accuracy: 1.0000 - val_loss: 3.5548 - val_accuracy: 0.8379\n",
            "Epoch 171/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.5694e-10 - accuracy: 1.0000 - val_loss: 3.5604 - val_accuracy: 0.8380\n",
            "Epoch 172/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 9.0101e-10 - accuracy: 1.0000 - val_loss: 3.5664 - val_accuracy: 0.8378\n",
            "Epoch 173/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.9070e-10 - accuracy: 1.0000 - val_loss: 3.5732 - val_accuracy: 0.8381\n",
            "Epoch 174/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.5632e-10 - accuracy: 1.0000 - val_loss: 3.5786 - val_accuracy: 0.8381\n",
            "Epoch 175/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.5393e-10 - accuracy: 1.0000 - val_loss: 3.5842 - val_accuracy: 0.8382\n",
            "Epoch 176/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 8.0635e-10 - accuracy: 1.0000 - val_loss: 3.5897 - val_accuracy: 0.8379\n",
            "Epoch 177/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 7.8145e-10 - accuracy: 1.0000 - val_loss: 3.5943 - val_accuracy: 0.8380\n",
            "Epoch 178/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 7.6999e-10 - accuracy: 1.0000 - val_loss: 3.5997 - val_accuracy: 0.8380\n",
            "Epoch 179/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 7.4386e-10 - accuracy: 1.0000 - val_loss: 3.6052 - val_accuracy: 0.8379\n",
            "Epoch 180/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 7.2535e-10 - accuracy: 1.0000 - val_loss: 3.6107 - val_accuracy: 0.8379\n",
            "Epoch 181/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.9713e-10 - accuracy: 1.0000 - val_loss: 3.6151 - val_accuracy: 0.8376\n",
            "Epoch 182/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.9366e-10 - accuracy: 1.0000 - val_loss: 3.6205 - val_accuracy: 0.8376\n",
            "Epoch 183/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.8015e-10 - accuracy: 1.0000 - val_loss: 3.6245 - val_accuracy: 0.8376\n",
            "Epoch 184/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.4312e-10 - accuracy: 1.0000 - val_loss: 3.6300 - val_accuracy: 0.8378\n",
            "Epoch 185/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.5252e-10 - accuracy: 1.0000 - val_loss: 3.6339 - val_accuracy: 0.8375\n",
            "Epoch 186/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 6.2806e-10 - accuracy: 1.0000 - val_loss: 3.6389 - val_accuracy: 0.8378\n",
            "Epoch 187/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.8964e-10 - accuracy: 1.0000 - val_loss: 3.6433 - val_accuracy: 0.8376\n",
            "Epoch 188/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 6.1403e-10 - accuracy: 1.0000 - val_loss: 3.6477 - val_accuracy: 0.8378\n",
            "Epoch 189/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 5.7793e-10 - accuracy: 1.0000 - val_loss: 3.6511 - val_accuracy: 0.8376\n",
            "Epoch 190/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.6744e-10 - accuracy: 1.0000 - val_loss: 3.6554 - val_accuracy: 0.8378\n",
            "Epoch 191/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.7141e-10 - accuracy: 1.0000 - val_loss: 3.6589 - val_accuracy: 0.8376\n",
            "Epoch 192/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.4840e-10 - accuracy: 1.0000 - val_loss: 3.6637 - val_accuracy: 0.8376\n",
            "Epoch 193/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.3742e-10 - accuracy: 1.0000 - val_loss: 3.6674 - val_accuracy: 0.8380\n",
            "Epoch 194/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.4402e-10 - accuracy: 1.0000 - val_loss: 3.6705 - val_accuracy: 0.8378\n",
            "Epoch 195/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.2377e-10 - accuracy: 1.0000 - val_loss: 3.6745 - val_accuracy: 0.8379\n",
            "Epoch 196/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.0848e-10 - accuracy: 1.0000 - val_loss: 3.6788 - val_accuracy: 0.8380\n",
            "Epoch 197/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 5.1298e-10 - accuracy: 1.0000 - val_loss: 3.6812 - val_accuracy: 0.8376\n",
            "Epoch 198/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 4.8277e-10 - accuracy: 1.0000 - val_loss: 3.6857 - val_accuracy: 0.8376\n",
            "Epoch 199/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.9320e-10 - accuracy: 1.0000 - val_loss: 3.6893 - val_accuracy: 0.8380\n",
            "Epoch 200/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 4.8087e-10 - accuracy: 1.0000 - val_loss: 3.6933 - val_accuracy: 0.8378\n",
            "Epoch 201/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.6356e-10 - accuracy: 1.0000 - val_loss: 3.6959 - val_accuracy: 0.8376\n",
            "Epoch 202/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 4.6280e-10 - accuracy: 1.0000 - val_loss: 3.7003 - val_accuracy: 0.8380\n",
            "Epoch 203/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.6181e-10 - accuracy: 1.0000 - val_loss: 3.7031 - val_accuracy: 0.8379\n",
            "Epoch 204/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.5178e-10 - accuracy: 1.0000 - val_loss: 3.7061 - val_accuracy: 0.8376\n",
            "Epoch 205/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 4.4090e-10 - accuracy: 1.0000 - val_loss: 3.7103 - val_accuracy: 0.8378\n",
            "Epoch 206/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.3632e-10 - accuracy: 1.0000 - val_loss: 3.7138 - val_accuracy: 0.8381\n",
            "Epoch 207/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.3047e-10 - accuracy: 1.0000 - val_loss: 3.7157 - val_accuracy: 0.8378\n",
            "Epoch 208/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.2287e-10 - accuracy: 1.0000 - val_loss: 3.7198 - val_accuracy: 0.8378\n",
            "Epoch 209/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.2253e-10 - accuracy: 1.0000 - val_loss: 3.7231 - val_accuracy: 0.8379\n",
            "Epoch 210/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.0578e-10 - accuracy: 1.0000 - val_loss: 3.7256 - val_accuracy: 0.8380\n",
            "Epoch 211/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.0917e-10 - accuracy: 1.0000 - val_loss: 3.7283 - val_accuracy: 0.8380\n",
            "Epoch 212/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 4.0147e-10 - accuracy: 1.0000 - val_loss: 3.7309 - val_accuracy: 0.8381\n",
            "Epoch 213/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.9118e-10 - accuracy: 1.0000 - val_loss: 3.7341 - val_accuracy: 0.8378\n",
            "Epoch 214/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.9021e-10 - accuracy: 1.0000 - val_loss: 3.7385 - val_accuracy: 0.8381\n",
            "Epoch 215/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.9708e-10 - accuracy: 1.0000 - val_loss: 3.7406 - val_accuracy: 0.8379\n",
            "Epoch 216/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.8242e-10 - accuracy: 1.0000 - val_loss: 3.7430 - val_accuracy: 0.8379\n",
            "Epoch 217/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.7261e-10 - accuracy: 1.0000 - val_loss: 3.7467 - val_accuracy: 0.8379\n",
            "Epoch 218/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.7284e-10 - accuracy: 1.0000 - val_loss: 3.7482 - val_accuracy: 0.8378\n",
            "Epoch 219/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.6869e-10 - accuracy: 1.0000 - val_loss: 3.7521 - val_accuracy: 0.8376\n",
            "Epoch 220/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.6478e-10 - accuracy: 1.0000 - val_loss: 3.7542 - val_accuracy: 0.8380\n",
            "Epoch 221/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.6379e-10 - accuracy: 1.0000 - val_loss: 3.7568 - val_accuracy: 0.8379\n",
            "Epoch 222/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.5383e-10 - accuracy: 1.0000 - val_loss: 3.7604 - val_accuracy: 0.8380\n",
            "Epoch 223/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.5014e-10 - accuracy: 1.0000 - val_loss: 3.7617 - val_accuracy: 0.8379\n",
            "Epoch 224/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.4473e-10 - accuracy: 1.0000 - val_loss: 3.7644 - val_accuracy: 0.8378\n",
            "Epoch 225/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.4678e-10 - accuracy: 1.0000 - val_loss: 3.7658 - val_accuracy: 0.8378\n",
            "Epoch 226/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.4275e-10 - accuracy: 1.0000 - val_loss: 3.7695 - val_accuracy: 0.8376\n",
            "Epoch 227/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.3100e-10 - accuracy: 1.0000 - val_loss: 3.7708 - val_accuracy: 0.8376\n",
            "Epoch 228/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.3707e-10 - accuracy: 1.0000 - val_loss: 3.7754 - val_accuracy: 0.8381\n",
            "Epoch 229/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.2746e-10 - accuracy: 1.0000 - val_loss: 3.7752 - val_accuracy: 0.8378\n",
            "Epoch 230/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.3631e-10 - accuracy: 1.0000 - val_loss: 3.7786 - val_accuracy: 0.8378\n",
            "Epoch 231/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.2150e-10 - accuracy: 1.0000 - val_loss: 3.7818 - val_accuracy: 0.8378\n",
            "Epoch 232/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.1795e-10 - accuracy: 1.0000 - val_loss: 3.7824 - val_accuracy: 0.8378\n",
            "Epoch 233/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.2148e-10 - accuracy: 1.0000 - val_loss: 3.7868 - val_accuracy: 0.8378\n",
            "Epoch 234/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.1202e-10 - accuracy: 1.0000 - val_loss: 3.7879 - val_accuracy: 0.8378\n",
            "Epoch 235/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.1623e-10 - accuracy: 1.0000 - val_loss: 3.7897 - val_accuracy: 0.8378\n",
            "Epoch 236/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.0402e-10 - accuracy: 1.0000 - val_loss: 3.7921 - val_accuracy: 0.8376\n",
            "Epoch 237/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 3.1716e-10 - accuracy: 1.0000 - val_loss: 3.7952 - val_accuracy: 0.8378\n",
            "Epoch 238/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.9936e-10 - accuracy: 1.0000 - val_loss: 3.7961 - val_accuracy: 0.8378\n",
            "Epoch 239/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 3.0128e-10 - accuracy: 1.0000 - val_loss: 3.7985 - val_accuracy: 0.8378\n",
            "Epoch 240/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.9577e-10 - accuracy: 1.0000 - val_loss: 3.8007 - val_accuracy: 0.8376\n",
            "Epoch 241/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.9966e-10 - accuracy: 1.0000 - val_loss: 3.8025 - val_accuracy: 0.8376\n",
            "Epoch 242/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.9396e-10 - accuracy: 1.0000 - val_loss: 3.8036 - val_accuracy: 0.8376\n",
            "Epoch 243/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.9631e-10 - accuracy: 1.0000 - val_loss: 3.8062 - val_accuracy: 0.8378\n",
            "Epoch 244/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.8638e-10 - accuracy: 1.0000 - val_loss: 3.8073 - val_accuracy: 0.8378\n",
            "Epoch 245/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.8907e-10 - accuracy: 1.0000 - val_loss: 3.8091 - val_accuracy: 0.8378\n",
            "Epoch 246/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.8345e-10 - accuracy: 1.0000 - val_loss: 3.8118 - val_accuracy: 0.8378\n",
            "Epoch 247/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.8171e-10 - accuracy: 1.0000 - val_loss: 3.8133 - val_accuracy: 0.8379\n",
            "Epoch 248/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.8693e-10 - accuracy: 1.0000 - val_loss: 3.8162 - val_accuracy: 0.8378\n",
            "Epoch 249/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.7368e-10 - accuracy: 1.0000 - val_loss: 3.8162 - val_accuracy: 0.8376\n",
            "Epoch 250/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.7861e-10 - accuracy: 1.0000 - val_loss: 3.8182 - val_accuracy: 0.8378\n",
            "Epoch 251/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.7634e-10 - accuracy: 1.0000 - val_loss: 3.8200 - val_accuracy: 0.8378\n",
            "Epoch 252/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.7363e-10 - accuracy: 1.0000 - val_loss: 3.8215 - val_accuracy: 0.8379\n",
            "Epoch 253/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.7262e-10 - accuracy: 1.0000 - val_loss: 3.8227 - val_accuracy: 0.8378\n",
            "Epoch 254/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.6475e-10 - accuracy: 1.0000 - val_loss: 3.8247 - val_accuracy: 0.8376\n",
            "Epoch 255/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.6495e-10 - accuracy: 1.0000 - val_loss: 3.8274 - val_accuracy: 0.8379\n",
            "Epoch 256/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.6639e-10 - accuracy: 1.0000 - val_loss: 3.8276 - val_accuracy: 0.8378\n",
            "Epoch 257/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.7177e-10 - accuracy: 1.0000 - val_loss: 3.8287 - val_accuracy: 0.8378\n",
            "Epoch 258/500\n",
            "156/156 [==============================] - 7s 44ms/step - loss: 2.5667e-10 - accuracy: 1.0000 - val_loss: 3.8308 - val_accuracy: 0.8378\n",
            "Epoch 259/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.6454e-10 - accuracy: 1.0000 - val_loss: 3.8320 - val_accuracy: 0.8376\n",
            "Epoch 260/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.5294e-10 - accuracy: 1.0000 - val_loss: 3.8347 - val_accuracy: 0.8379\n",
            "Epoch 261/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.6018e-10 - accuracy: 1.0000 - val_loss: 3.8350 - val_accuracy: 0.8378\n",
            "Epoch 262/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.5523e-10 - accuracy: 1.0000 - val_loss: 3.8368 - val_accuracy: 0.8376\n",
            "Epoch 263/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.5395e-10 - accuracy: 1.0000 - val_loss: 3.8384 - val_accuracy: 0.8378\n",
            "Epoch 264/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4907e-10 - accuracy: 1.0000 - val_loss: 3.8408 - val_accuracy: 0.8379\n",
            "Epoch 265/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.5227e-10 - accuracy: 1.0000 - val_loss: 3.8411 - val_accuracy: 0.8378\n",
            "Epoch 266/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.5201e-10 - accuracy: 1.0000 - val_loss: 3.8434 - val_accuracy: 0.8379\n",
            "Epoch 267/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4671e-10 - accuracy: 1.0000 - val_loss: 3.8446 - val_accuracy: 0.8379\n",
            "Epoch 268/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4908e-10 - accuracy: 1.0000 - val_loss: 3.8461 - val_accuracy: 0.8378\n",
            "Epoch 269/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4496e-10 - accuracy: 1.0000 - val_loss: 3.8472 - val_accuracy: 0.8381\n",
            "Epoch 270/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4336e-10 - accuracy: 1.0000 - val_loss: 3.8491 - val_accuracy: 0.8379\n",
            "Epoch 271/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4386e-10 - accuracy: 1.0000 - val_loss: 3.8512 - val_accuracy: 0.8380\n",
            "Epoch 272/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4378e-10 - accuracy: 1.0000 - val_loss: 3.8513 - val_accuracy: 0.8380\n",
            "Epoch 273/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3524e-10 - accuracy: 1.0000 - val_loss: 3.8530 - val_accuracy: 0.8380\n",
            "Epoch 274/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3719e-10 - accuracy: 1.0000 - val_loss: 3.8550 - val_accuracy: 0.8381\n",
            "Epoch 275/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.4255e-10 - accuracy: 1.0000 - val_loss: 3.8562 - val_accuracy: 0.8380\n",
            "Epoch 276/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3316e-10 - accuracy: 1.0000 - val_loss: 3.8575 - val_accuracy: 0.8379\n",
            "Epoch 277/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3873e-10 - accuracy: 1.0000 - val_loss: 3.8586 - val_accuracy: 0.8381\n",
            "Epoch 278/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3198e-10 - accuracy: 1.0000 - val_loss: 3.8591 - val_accuracy: 0.8380\n",
            "Epoch 279/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2887e-10 - accuracy: 1.0000 - val_loss: 3.8607 - val_accuracy: 0.8380\n",
            "Epoch 280/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3969e-10 - accuracy: 1.0000 - val_loss: 3.8620 - val_accuracy: 0.8380\n",
            "Epoch 281/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2776e-10 - accuracy: 1.0000 - val_loss: 3.8624 - val_accuracy: 0.8380\n",
            "Epoch 282/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 3.8636 - val_accuracy: 0.8380\n",
            "Epoch 283/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3362e-10 - accuracy: 1.0000 - val_loss: 3.8651 - val_accuracy: 0.8380\n",
            "Epoch 284/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2405e-10 - accuracy: 1.0000 - val_loss: 3.8673 - val_accuracy: 0.8379\n",
            "Epoch 285/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.3009e-10 - accuracy: 1.0000 - val_loss: 3.8683 - val_accuracy: 0.8380\n",
            "Epoch 286/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2282e-10 - accuracy: 1.0000 - val_loss: 3.8696 - val_accuracy: 0.8380\n",
            "Epoch 287/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2043e-10 - accuracy: 1.0000 - val_loss: 3.8711 - val_accuracy: 0.8381\n",
            "Epoch 288/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2400e-10 - accuracy: 1.0000 - val_loss: 3.8725 - val_accuracy: 0.8381\n",
            "Epoch 289/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2289e-10 - accuracy: 1.0000 - val_loss: 3.8741 - val_accuracy: 0.8381\n",
            "Epoch 290/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2201e-10 - accuracy: 1.0000 - val_loss: 3.8756 - val_accuracy: 0.8381\n",
            "Epoch 291/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1720e-10 - accuracy: 1.0000 - val_loss: 3.8753 - val_accuracy: 0.8380\n",
            "Epoch 292/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2119e-10 - accuracy: 1.0000 - val_loss: 3.8764 - val_accuracy: 0.8380\n",
            "Epoch 293/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1596e-10 - accuracy: 1.0000 - val_loss: 3.8781 - val_accuracy: 0.8380\n",
            "Epoch 294/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1448e-10 - accuracy: 1.0000 - val_loss: 3.8797 - val_accuracy: 0.8382\n",
            "Epoch 295/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.2164e-10 - accuracy: 1.0000 - val_loss: 3.8806 - val_accuracy: 0.8380\n",
            "Epoch 296/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1460e-10 - accuracy: 1.0000 - val_loss: 3.8817 - val_accuracy: 0.8379\n",
            "Epoch 297/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1071e-10 - accuracy: 1.0000 - val_loss: 3.8829 - val_accuracy: 0.8380\n",
            "Epoch 298/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1551e-10 - accuracy: 1.0000 - val_loss: 3.8835 - val_accuracy: 0.8379\n",
            "Epoch 299/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1426e-10 - accuracy: 1.0000 - val_loss: 3.8845 - val_accuracy: 0.8380\n",
            "Epoch 300/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0851e-10 - accuracy: 1.0000 - val_loss: 3.8856 - val_accuracy: 0.8380\n",
            "Epoch 301/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0894e-10 - accuracy: 1.0000 - val_loss: 3.8865 - val_accuracy: 0.8380\n",
            "Epoch 302/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0949e-10 - accuracy: 1.0000 - val_loss: 3.8875 - val_accuracy: 0.8380\n",
            "Epoch 303/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0666e-10 - accuracy: 1.0000 - val_loss: 3.8890 - val_accuracy: 0.8380\n",
            "Epoch 304/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.1140e-10 - accuracy: 1.0000 - val_loss: 3.8899 - val_accuracy: 0.8380\n",
            "Epoch 305/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0706e-10 - accuracy: 1.0000 - val_loss: 3.8910 - val_accuracy: 0.8380\n",
            "Epoch 306/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0784e-10 - accuracy: 1.0000 - val_loss: 3.8920 - val_accuracy: 0.8380\n",
            "Epoch 307/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0265e-10 - accuracy: 1.0000 - val_loss: 3.8935 - val_accuracy: 0.8380\n",
            "Epoch 308/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0751e-10 - accuracy: 1.0000 - val_loss: 3.8940 - val_accuracy: 0.8380\n",
            "Epoch 309/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0049e-10 - accuracy: 1.0000 - val_loss: 3.8956 - val_accuracy: 0.8380\n",
            "Epoch 310/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0635e-10 - accuracy: 1.0000 - val_loss: 3.8965 - val_accuracy: 0.8380\n",
            "Epoch 311/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0335e-10 - accuracy: 1.0000 - val_loss: 3.8967 - val_accuracy: 0.8380\n",
            "Epoch 312/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0017e-10 - accuracy: 1.0000 - val_loss: 3.8980 - val_accuracy: 0.8379\n",
            "Epoch 313/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0205e-10 - accuracy: 1.0000 - val_loss: 3.8993 - val_accuracy: 0.8380\n",
            "Epoch 314/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0207e-10 - accuracy: 1.0000 - val_loss: 3.9002 - val_accuracy: 0.8380\n",
            "Epoch 315/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9728e-10 - accuracy: 1.0000 - val_loss: 3.9010 - val_accuracy: 0.8380\n",
            "Epoch 316/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9814e-10 - accuracy: 1.0000 - val_loss: 3.9017 - val_accuracy: 0.8380\n",
            "Epoch 317/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9721e-10 - accuracy: 1.0000 - val_loss: 3.9028 - val_accuracy: 0.8380\n",
            "Epoch 318/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9587e-10 - accuracy: 1.0000 - val_loss: 3.9037 - val_accuracy: 0.8380\n",
            "Epoch 319/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 2.0134e-10 - accuracy: 1.0000 - val_loss: 3.9049 - val_accuracy: 0.8381\n",
            "Epoch 320/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9610e-10 - accuracy: 1.0000 - val_loss: 3.9062 - val_accuracy: 0.8380\n",
            "Epoch 321/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9816e-10 - accuracy: 1.0000 - val_loss: 3.9064 - val_accuracy: 0.8380\n",
            "Epoch 322/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9101e-10 - accuracy: 1.0000 - val_loss: 3.9080 - val_accuracy: 0.8380\n",
            "Epoch 323/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9708e-10 - accuracy: 1.0000 - val_loss: 3.9081 - val_accuracy: 0.8379\n",
            "Epoch 324/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9251e-10 - accuracy: 1.0000 - val_loss: 3.9093 - val_accuracy: 0.8379\n",
            "Epoch 325/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8966e-10 - accuracy: 1.0000 - val_loss: 3.9106 - val_accuracy: 0.8380\n",
            "Epoch 326/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9192e-10 - accuracy: 1.0000 - val_loss: 3.9112 - val_accuracy: 0.8381\n",
            "Epoch 327/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9029e-10 - accuracy: 1.0000 - val_loss: 3.9121 - val_accuracy: 0.8380\n",
            "Epoch 328/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9461e-10 - accuracy: 1.0000 - val_loss: 3.9131 - val_accuracy: 0.8380\n",
            "Epoch 329/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9381e-10 - accuracy: 1.0000 - val_loss: 3.9137 - val_accuracy: 0.8379\n",
            "Epoch 330/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8999e-10 - accuracy: 1.0000 - val_loss: 3.9147 - val_accuracy: 0.8380\n",
            "Epoch 331/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8964e-10 - accuracy: 1.0000 - val_loss: 3.9154 - val_accuracy: 0.8379\n",
            "Epoch 332/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8619e-10 - accuracy: 1.0000 - val_loss: 3.9159 - val_accuracy: 0.8381\n",
            "Epoch 333/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.9001e-10 - accuracy: 1.0000 - val_loss: 3.9173 - val_accuracy: 0.8380\n",
            "Epoch 334/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8472e-10 - accuracy: 1.0000 - val_loss: 3.9177 - val_accuracy: 0.8379\n",
            "Epoch 335/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8643e-10 - accuracy: 1.0000 - val_loss: 3.9190 - val_accuracy: 0.8381\n",
            "Epoch 336/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8704e-10 - accuracy: 1.0000 - val_loss: 3.9192 - val_accuracy: 0.8379\n",
            "Epoch 337/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8762e-10 - accuracy: 1.0000 - val_loss: 3.9202 - val_accuracy: 0.8379\n",
            "Epoch 338/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8356e-10 - accuracy: 1.0000 - val_loss: 3.9218 - val_accuracy: 0.8380\n",
            "Epoch 339/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8351e-10 - accuracy: 1.0000 - val_loss: 3.9224 - val_accuracy: 0.8380\n",
            "Epoch 340/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8577e-10 - accuracy: 1.0000 - val_loss: 3.9230 - val_accuracy: 0.8380\n",
            "Epoch 341/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8415e-10 - accuracy: 1.0000 - val_loss: 3.9242 - val_accuracy: 0.8381\n",
            "Epoch 342/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8240e-10 - accuracy: 1.0000 - val_loss: 3.9248 - val_accuracy: 0.8379\n",
            "Epoch 343/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8154e-10 - accuracy: 1.0000 - val_loss: 3.9256 - val_accuracy: 0.8380\n",
            "Epoch 344/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8242e-10 - accuracy: 1.0000 - val_loss: 3.9260 - val_accuracy: 0.8380\n",
            "Epoch 345/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8172e-10 - accuracy: 1.0000 - val_loss: 3.9271 - val_accuracy: 0.8380\n",
            "Epoch 346/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7763e-10 - accuracy: 1.0000 - val_loss: 3.9277 - val_accuracy: 0.8379\n",
            "Epoch 347/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8110e-10 - accuracy: 1.0000 - val_loss: 3.9288 - val_accuracy: 0.8380\n",
            "Epoch 348/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8029e-10 - accuracy: 1.0000 - val_loss: 3.9295 - val_accuracy: 0.8380\n",
            "Epoch 349/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7869e-10 - accuracy: 1.0000 - val_loss: 3.9298 - val_accuracy: 0.8380\n",
            "Epoch 350/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8176e-10 - accuracy: 1.0000 - val_loss: 3.9307 - val_accuracy: 0.8380\n",
            "Epoch 351/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8134e-10 - accuracy: 1.0000 - val_loss: 3.9314 - val_accuracy: 0.8381\n",
            "Epoch 352/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7605e-10 - accuracy: 1.0000 - val_loss: 3.9319 - val_accuracy: 0.8379\n",
            "Epoch 353/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7956e-10 - accuracy: 1.0000 - val_loss: 3.9327 - val_accuracy: 0.8380\n",
            "Epoch 354/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7479e-10 - accuracy: 1.0000 - val_loss: 3.9335 - val_accuracy: 0.8380\n",
            "Epoch 355/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7461e-10 - accuracy: 1.0000 - val_loss: 3.9337 - val_accuracy: 0.8380\n",
            "Epoch 356/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7673e-10 - accuracy: 1.0000 - val_loss: 3.9348 - val_accuracy: 0.8379\n",
            "Epoch 357/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7765e-10 - accuracy: 1.0000 - val_loss: 3.9358 - val_accuracy: 0.8380\n",
            "Epoch 358/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6940e-10 - accuracy: 1.0000 - val_loss: 3.9368 - val_accuracy: 0.8379\n",
            "Epoch 359/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.8025e-10 - accuracy: 1.0000 - val_loss: 3.9373 - val_accuracy: 0.8379\n",
            "Epoch 360/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7343e-10 - accuracy: 1.0000 - val_loss: 3.9380 - val_accuracy: 0.8379\n",
            "Epoch 361/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7131e-10 - accuracy: 1.0000 - val_loss: 3.9390 - val_accuracy: 0.8380\n",
            "Epoch 362/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7438e-10 - accuracy: 1.0000 - val_loss: 3.9399 - val_accuracy: 0.8379\n",
            "Epoch 363/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7303e-10 - accuracy: 1.0000 - val_loss: 3.9405 - val_accuracy: 0.8379\n",
            "Epoch 364/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 3.9410 - val_accuracy: 0.8379\n",
            "Epoch 365/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7052e-10 - accuracy: 1.0000 - val_loss: 3.9412 - val_accuracy: 0.8379\n",
            "Epoch 366/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7418e-10 - accuracy: 1.0000 - val_loss: 3.9422 - val_accuracy: 0.8379\n",
            "Epoch 367/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6773e-10 - accuracy: 1.0000 - val_loss: 3.9431 - val_accuracy: 0.8379\n",
            "Epoch 368/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7143e-10 - accuracy: 1.0000 - val_loss: 3.9436 - val_accuracy: 0.8380\n",
            "Epoch 369/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7077e-10 - accuracy: 1.0000 - val_loss: 3.9445 - val_accuracy: 0.8379\n",
            "Epoch 370/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6932e-10 - accuracy: 1.0000 - val_loss: 3.9450 - val_accuracy: 0.8379\n",
            "Epoch 371/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6841e-10 - accuracy: 1.0000 - val_loss: 3.9457 - val_accuracy: 0.8379\n",
            "Epoch 372/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6927e-10 - accuracy: 1.0000 - val_loss: 3.9458 - val_accuracy: 0.8379\n",
            "Epoch 373/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7108e-10 - accuracy: 1.0000 - val_loss: 3.9468 - val_accuracy: 0.8379\n",
            "Epoch 374/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6709e-10 - accuracy: 1.0000 - val_loss: 3.9475 - val_accuracy: 0.8380\n",
            "Epoch 375/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6598e-10 - accuracy: 1.0000 - val_loss: 3.9485 - val_accuracy: 0.8379\n",
            "Epoch 376/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.7050e-10 - accuracy: 1.0000 - val_loss: 3.9494 - val_accuracy: 0.8380\n",
            "Epoch 377/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6219e-10 - accuracy: 1.0000 - val_loss: 3.9496 - val_accuracy: 0.8380\n",
            "Epoch 378/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6689e-10 - accuracy: 1.0000 - val_loss: 3.9503 - val_accuracy: 0.8379\n",
            "Epoch 379/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6858e-10 - accuracy: 1.0000 - val_loss: 3.9509 - val_accuracy: 0.8379\n",
            "Epoch 380/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6853e-10 - accuracy: 1.0000 - val_loss: 3.9515 - val_accuracy: 0.8380\n",
            "Epoch 381/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6037e-10 - accuracy: 1.0000 - val_loss: 3.9524 - val_accuracy: 0.8379\n",
            "Epoch 382/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6914e-10 - accuracy: 1.0000 - val_loss: 3.9527 - val_accuracy: 0.8379\n",
            "Epoch 383/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6310e-10 - accuracy: 1.0000 - val_loss: 3.9533 - val_accuracy: 0.8380\n",
            "Epoch 384/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6523e-10 - accuracy: 1.0000 - val_loss: 3.9538 - val_accuracy: 0.8381\n",
            "Epoch 385/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6127e-10 - accuracy: 1.0000 - val_loss: 3.9548 - val_accuracy: 0.8380\n",
            "Epoch 386/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6383e-10 - accuracy: 1.0000 - val_loss: 3.9552 - val_accuracy: 0.8380\n",
            "Epoch 387/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6369e-10 - accuracy: 1.0000 - val_loss: 3.9560 - val_accuracy: 0.8379\n",
            "Epoch 388/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6243e-10 - accuracy: 1.0000 - val_loss: 3.9564 - val_accuracy: 0.8379\n",
            "Epoch 389/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6653e-10 - accuracy: 1.0000 - val_loss: 3.9569 - val_accuracy: 0.8380\n",
            "Epoch 390/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.5789e-10 - accuracy: 1.0000 - val_loss: 3.9578 - val_accuracy: 0.8380\n",
            "Epoch 391/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6232e-10 - accuracy: 1.0000 - val_loss: 3.9584 - val_accuracy: 0.8380\n",
            "Epoch 392/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6330e-10 - accuracy: 1.0000 - val_loss: 3.9590 - val_accuracy: 0.8380\n",
            "Epoch 393/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.5809e-10 - accuracy: 1.0000 - val_loss: 3.9598 - val_accuracy: 0.8379\n",
            "Epoch 394/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6234e-10 - accuracy: 1.0000 - val_loss: 3.9604 - val_accuracy: 0.8379\n",
            "Epoch 395/500\n",
            "156/156 [==============================] - 7s 46ms/step - loss: 1.5913e-10 - accuracy: 1.0000 - val_loss: 3.9609 - val_accuracy: 0.8380\n",
            "Epoch 396/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.5659e-10 - accuracy: 1.0000 - val_loss: 3.9614 - val_accuracy: 0.8380\n",
            "Epoch 397/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.6127e-10 - accuracy: 1.0000 - val_loss: 3.9623 - val_accuracy: 0.8380\n",
            "Epoch 398/500\n",
            "156/156 [==============================] - 7s 45ms/step - loss: 1.5897e-10 - accuracy: 1.0000 - val_loss: 3.9628 - val_accuracy: 0.8380\n",
            "Epoch 399/500\n",
            " 13/156 [=>............................] - ETA: 6s - loss: 1.8488e-10 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 78125.0 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r156/156 [==============================] - 1s 9ms/step - loss: 1.8732e-10 - accuracy: 1.0000 - val_loss: 3.9628 - val_accuracy: 0.8380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resultados"
      ],
      "metadata": {
        "id": "XtEba7eoPoGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "predict = model.predict(X_test_pad)\n",
        "y_pred = np.argmax(predict, axis = 1)\n",
        "y_true = np.argmax(y_test, axis = 1)\n",
        "\n",
        "print(\"Acurácia:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision: \", precision_score(y_true, y_pred, average=None))\n",
        "print(\"Recall: \", recall_score(y_true, y_pred, average=None))\n",
        "print(\"F1 Score: \", f1_score(y_true, y_pred, average=None))\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N7PRgroP0Pk",
        "outputId": "79225fe2-a5de-4351-ab0e-f8b8b3aa0732"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n",
            "Acurácia: 0.8412\n",
            "Precision:  [0.83661692 0.84582915]\n",
            "Recall:  [0.84570509 0.83674687]\n",
            "F1 Score:  [0.84113645 0.84126349]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      4971\n",
            "           1       0.85      0.84      0.84      5029\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = np.shape(history.history['accuracy'])[0]\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Model', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(1,epochs+1))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, epochs+1, 100))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, epochs+1, 100))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "oWTzFMeYQv7W",
        "outputId": "03edb10a-947f-4dc3-8284-151fbc4f9c32"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_true, y_pred)\n",
        "#sns.heatmap(cm,annot=True,fmt='d')\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues').set(ylabel='True Label', xlabel='Predicted Label')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "M2gtW4GFPgOs",
        "outputId": "a6d36542-a105-4555-bcff-d7f734cd650d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(33.0, 0.5, 'True Label'), Text(0.5, 15.0, 'Predicted Label')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "3e49519f7b09f4aa352b7cd5070833d10fcb0975d02a6ca8700d1301f185eb2b"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}